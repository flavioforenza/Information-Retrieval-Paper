\section{\centering{"Query expansion using Language Models"}}

\begin{frame}{INTRODUCTION}
    Nowadays, searching the web for information appears to be one of the 
    simplest operations to perform. The difficulty perceived by the user in 
    formulating a query has been gradually reduced by techniques capable of 
    guiding his writing towards a correct generation of a query. These 
    techniques allow to improve the performance of information search 
    systems.
\end{frame}

\begin{frame}{GOAL}
    The purpose of this project is to be able to experiment with the use of 
    one of the most famous techniques, already present at the state of the 
    art, able to "assist" the user in formulating a correct query: {\bfseries Language 
    Modelling}. Query expansion can be done using this concept to return a 
    corpus of relevant documents. 
\end{frame}

\begin{frame}{DATASET DESCRIPTION}
    \begin{minipage}{\linewidth}
        \centering
        \begin{minipage}{0.45\linewidth}
            The dataset used for the experiments is the famous \emph{Recipes1M+} \footnotemark[1], a collection 
            created by MIT, consisting of more than one million culinary recipes. Of 
            all these recipes, only a subset of 51235 documents of it was used due to their 
            informative content which best fits the purpose of this study. The information 
            about the line distributions for each recipe indicates that the instruction 
            field contains a higher number than the information contained in the ingredients 
            field.
        \end{minipage}
        \hspace{0.05\linewidth}
        \begin{minipage}{0.47\linewidth}
            \begin{figure}[h!]
                \centering
                \includegraphics[width =\linewidth]{displot.png}
                \centering
                \caption{Distributions of lines per ingredients and instructions.}
                \label{distributions}
            \end{figure}
        \end{minipage}
    \end{minipage}
    \footnotetext[1]{\tiny J.Marin, A.Biswas, F.Ofli, N.Hynes, A.Salvador, Y.Aytar, I.Weber and A.Torralba, "Recipe1M+: A Dataset for Learning Cross-Modal Embeddings for Cooking Recipes and Food Images", IEEE Trans. Pattern Anal. Mach. Intell., 2019}
\end{frame}

\begin{frame}{RANKING GENERATION}
    The first step is based on choosing a random query, which resembles the title of one of the existing recipes. Subsequently, thanks to the combination of the tf-idf method and the cosine similarity metric, it is possible to generate the first ranking of documents ordered according to relevance with the query. The threshold chosen, for the selection of the most relevant documents, will correspond to the weight assigned by the tf-idf to the target document.
    \begin{minipage}{\linewidth}
        \centering
        \begin{minipage}{0.45\linewidth}
            \begin{block}{\centering tf-idf}
                \centering \small $ TfIdf(q_t,d) = tf_{q_t,d} \log\frac{N}{df_{q_t}}$
            \end{block}
        \end{minipage}
        \hspace{0.05\linewidth}
        \begin{minipage}{0.45\linewidth}
            \begin{block}{\centering Cosine similarity}
                \centering \small $ cosine(q,d) = \frac{\sum_{i=1}^Nqd_i}{\sqrt{\sum_{i=1}^Nq^2}\sqrt{\sum_{i=1}^Nd_i^2}} $
            \end{block}
        \end{minipage}
    \end{minipage}
\end{frame}

\begin{frame}{RANKING EVALUATION}
    The evaluation of the ranking of relevant documents was carried out considering 
    as the entity, of each single document, its category of belonging\footfullcite{16} 
    (dessert, salad, beverage, etc.). The search for each category takes place 
    in two methods, with two different libraries:
    \begin{itemize}
        \item \emph{Scrape Schema Recipe}
        \item \emph{USDA} (United States Department of Agricolture)
    \end{itemize}
    \begin{minipage}{\linewidth}
        \centering
        \begin{minipage}{0.50\linewidth}
            \begin{table}[]
                \centering
                \begin{adjustbox}{max width=\textwidth}
                \begin{tabular}{|c||c|c|c||c||c||}
                    \hline
                    \multirow{2}{*}{\bfseries{Queries}} & \multicolumn{3}{c||}{\bfseries{Scrape Schema Recipe}} & \multicolumn{1}{c||}{\bfseries{USDA}} & \multicolumn{1}{c||}{\bfseries{Mixed (Scrape+USDA)}} \\            & \bfseries{Overestimate} & \bfseries{Underestimate} & \bfseries{Discarded} & \bfseries{}  & \bfseries{}\\
                    \hline
                    \hline
                    \RN{1} & 0.7520 & 0.3734 & 0.5958 & 0.9817 & 0.9947\\
                    \hline
                    \RN{2} & 0.9309 & 0.6780 & 0.9054 & 1.0 & 1.0\\
                    \hline 
                    \RN{3} & 0.7458 & 0.2746 & 0.5411 & 0.9797 & 0.9982\\
                    \hline
                    \RN{4} & 0.8939 &  0.5320 & 0.8433 & 0.9612 & 0.9870\\
                    \hline
                    \RN{5} & 0.8335 & 0.5033 & 0.7544 & 0.9940 & 0.9940\\
                    \hline
                    \hline
                    Average & 0.8312 & 0.4722 & 0.7280 & 0.9833 &  \bfseries 0.99478 \\
                    \hline
                \end{tabular}
                \end{adjustbox}
                \caption{Average Precision on each query for each method.}
                \label{avgp}
                \centering
            \end{table}
        \end{minipage}
        \begin{minipage}{0.40\linewidth}
            \begin{figure}[htbp]
                \centering
                \includegraphics[width =\linewidth]{11 DOCUMENTS WITH MIXED ENTITIES (SCRAPE+USDA).png}
                \centering
                \caption{Performance in terms of Precion, Recall and Interpolated Recall.}
                \label{Performance mixed approach}
                \centering
            \end{figure}
        \end{minipage}
    \end{minipage}
\end{frame}

\begin{frame}{LANGUAGE MODELS}
    For each document, present in the ranking, having a threshold greater 
    than or equal to the weight assigned to the target document, a language 
    models will be constructed consisting of a sequence of \emph{bi-grams}, with an 
    initial \emph{skip-grams} equal to two, with the relative count of every 
    occurrence.    
    \begin{block}{\centering Sentence probability (Bi-gram) and MLE}
        \begin{eqnarray}\label{MLE}
            P(q|d) & \approx & P(q|M_d) \nonumber \\
                   & \approx & \prod_i^n{P(w_i|w_{i-1})} \nonumber \\
                   & \approx & \frac{count(w_i,w_{i-1})}{\sum_{j=1}^n count(w_j,w_{i-1})} \nonumber \\
                   & = & \frac{count(w_i, w_{i-1})}{count(w_{i-1})}
        \end{eqnarray}
    \end{block}
\end{frame}

\begin{frame}{SMOOTHING METHODS}
    To avoid having a probability equal to zero, two smoothing techniques are calculated:
    \begin{minipage}{\linewidth}
        \centering
        \begin{minipage}{0.45\linewidth}
            \begin{block}{\centering Laplace Smoothing}
                \centering\small $ P(w_i|w_{i-1}) = \frac{count(w_{i-1})+1}{count(w_{i-1})+|V|} $
            \end{block}
        \end{minipage}
        \hspace{0.05\linewidth}
        \begin{minipage}{0.45\linewidth}
            \begin{block}{\centering Linear Interpolation Smoothing (Bi-grams)}
                \centering \scriptsize $ P(w_i|w_{i-1}) = \lambda P(q|M_d) + (1-\lambda)P(q|M_c) $
            \end{block}
        \end{minipage}
    \end{minipage}
    \begin{minipage}{\linewidth}
        \centering
        \begin{minipage}{0.45\linewidth}
            where:
            \begin{itemize}
                \item $\sum_i \lambda_i = 1$
                \item $M_d$: LM of the single document;
                \item $M_c$: LM of the entire collection of documents;
                \item $|V|$: \# unique words within the corpus of documents.
            \end{itemize}
        \end{minipage}
        \hspace{0.05\linewidth}
        \begin{minipage}{0.45\linewidth}
            \begin{figure}[H]
                \centering
                \includegraphics[width =0.11\linewidth]{vertical points.png}
                \centering
            \end{figure}
            \begin{block}{\centering Linear Interpolation Smoothing (Zero-grams)\footnotemark[3]}
                \centering \small $ P(w_i) = \lambda \frac{1}{|V|} + (1-\lambda)P(w_i) $
            \end{block}
        \end{minipage}
    \end{minipage}
    \footnotetext[3]{\tiny A.Gutnik, "Log-Linear Interpolation of Language Models", 2000}
\end{frame}

\begin{frame}[fragile]{CORE}
    \begin{minipage}{\linewidth}
        \centering
        \begin{minipage}{0.60\linewidth}
            \begin{algorithm}[H]
                \algsetup{linenosize=\tiny}
                \scriptsize
                \SetKwInOut{Input}{input}
                \SetKwInOut{Output}{output}
                \SetKwData{LMcoll}{LMcoll}
                \SetKwData{rankLpl}{rankLpl}
                \SetKwData{LMdocs}{LMdocs}
                \SetKwData{PerplexityLpl}{perplexityLpl}
                \SetKwData{rankLinInt}{rankLinInt}
                \SetKwData{Lamb1}{lamb1}
                \SetKwData{Lamb2}{lamb2}
                \SetKwData{Break}{break}
                \SetKwData{PerplexityInt}{perplexityInt}
                \SetKwFunction{ComputeLMdocs}{ComputeLMdocs}
                \SetKwFunction{ComputeLMcoll}{ComputeLMcoll}
                \SetKwFunction{LplSmoot}{LplSmoot}
                \SetKwFunction{Perplexity}{Perplexity}
                \SetKwFunction{LinInt}{LinInt}
                \Input{q}
                \Output{final\_ranking}
                \Parameter{LMtd}
                \BlankLine
                \For{$s \leftarrow 2$ \KwTo $10$}{
                    \LMdocs$\leftarrow$ \ComputeLMdocs{$s, query $}\;
                    \LMcoll$\leftarrow$ \ComputeLMcoll{$s, query $}\;
                    rankLpl $\leftarrow$ \LplSmoot($q,LMdocs$)\;
                    perplexityLpl $\leftarrow$ \PerplexityLpl($q, LMtd$)\;
                    lamb1, lamb2 $\leftarrow$ 0\;
                    \For{$i \leftarrow 0.1$ \KwTo $1.0$}{
                        rankLinInt $\leftarrow$ \LinInt($q, LMdocs, LMcoll$)\;
                        perplexityInt $\leftarrow$ \PerplexityInt($q, LMtd$)\;
                        lamb1 $\leftarrow$ 0.1 + i\;
                        lamb2 $\leftarrow$ 0.9 - i\;
                        \If{lamb2==0}{break\;}       
                    }
                }
                \vdots
                \emph{Search for the minimum index of the target document}\;
                final\_ranking $\leftarrow$ min(rankLpl[i],rankLinInt[i])\;
                \Return{final\_ranking}
            \caption{Best Ranking\label{IR}}
            \end{algorithm}
        \end{minipage}
        \hspace{0.01\linewidth}
        \begin{minipage}{0.37\linewidth}
            \scriptsize
            where:
            \begin{itemize}
                \item \emph{q}: query
                \item \emph{s}: skip-gram
                \item \emph{final\_ranking}: ranking containing the target document in the position closest to the first
                \item \emph{LMtd}: Language model of target document 
                \item \emph{LMdocs}: List of the language models of each document
                \item \emph{LMcoll}: language model of the entire collection of documents
                \item \emph{lamb1}: $\lambda_1$
                \item \emph{lamb2}: $\lambda_2$
            \end{itemize}
        \end{minipage}
    \end{minipage}    
\end{frame}

\begin{frame}{TERM-TERM MATRIX}
    As explained in \footfullcite{12}, two or more words are considered synonymous, or 
    semantically important, if their \emph{vectors}, represented in a multidimensional 
    space, have a high \emph{cosine similarity}. To find out, we need to build a 
    matrix of terms, called \emph{term-term matrix}, where the \emph{co-occurrences} 
    between the terms present in the relevant documents and in the query 
    will be reported. We can exploit the \emph{Language Model} of the entire corpus, of relevant documents, to derive co-occurrences.
    \begin{table}[h!]
        \centering
        \begin{adjustbox}{max width=10cm}
        \begin{tabular}{*{7}{|c}|}%%{|c|c|c|c|c|c|c|}
            \hline
            & variation & broccoli & cauliflower & toss & substitute & $\cdots$\\
            \hline
            variation & 0 & \bfseries{1} & 0 & 0 & 0 &$\cdots$\\
            broccoli & 0 & 0 & \bfseries{5} & 0 & 0 & $\cdots$\\
            cauliflower & 0 & 0 & 0 & \bfseries{1} & 0 & $\cdots$\\
            toss & 0 & 0 & 0 & 0 & \bfseries{1} &$\cdots$\\
            substitute & 0 & 0 & \bfseries{1} &0 & 0 &$\cdots$\\
            $\cdots$ & $\cdots$ & $\cdots$ & $\cdots$ & $\cdots$ & $\cdots$ & $\cdots$\\
            \hline
        \end{tabular}
        \end{adjustbox}
        \caption{Co-Occurrence of words in Term-Term Matrix.}
        \label{table accuracy}
    \end{table}
\end{frame}

\begin{frame}{POSITIVE POINTWISE MUTUAL INFORMATIONS (PPMI)}
    Pointwise Mutual Information (PMI) was used to evaluate the relationship between two words.
    Mutual Informations (PMI).
    \begin{block}{PMI}
        \small \emph{\say{PMI draws on the intuition that the best way to weigh the association between two words is to ask how much more the two words co-occur in our corpus than we would have a priori expected them to appear by chance.}\footnotemark[2]}
    \end{block}
    In this case, its \emph{"Positive"} version (PPMI) was used to be able to remove negative values.
    \begin{minipage}{\linewidth}
        \centering
        \begin{minipage}{0.40\linewidth}
            \begin{block}{\centering PMI}
                \centering \small $ PMI(x,y) = \log_2\frac{P(x,y)}{P(x)P(y)} $
            \end{block} 
        \end{minipage}
        \hspace{0.05\linewidth}
        \begin{minipage}{0.50\linewidth}
            \begin{block}{\centering PPMI}
                \centering \small $ PPMI(x,y) = \max(\log_2\frac{P(x,y)}{P(x)P(y)}, 0) $
            \end{block}
        \end{minipage}
    \end{minipage}
\end{frame}

\begin{frame}{SINGULAR VALUE DECOMPOSITION (SVD)}
    The term-term matrix presents a serious problem that affects 
    the performance of the system and the calculation of the cosine similarity: 
    the {\bfseries{sparsity}}. In order to reduce the sparsity, the \emph{Singular 
    Value Decomposition (SVD)} technique was applied.
    \begin{minipage}{\linewidth}
        \centering
        \begin{minipage}{0.20\linewidth}
            \begin{block}{}
                \centering $ A = USV^T $
            \end{block}
            \begin{block}{}
                \centering $ \mathcal{D} = U*S $
            \end{block}
            \begin{block}{}
                \centering $ \mathcal{T} = S*V^T $
            \end{block}
        \end{minipage}
        \hspace{0.05\linewidth}
        \begin{minipage}{0.60\linewidth}
            Where:
            \begin{itemize}
                \item \emph{A}: a $t\times d$ Term-Term Matrix decomposed into 3 sub-matrices.
                \item \emph{U}: a $t\times m$ matrix
                \item \emph{S}: a $m\times n$ matrix
                \item \emph{$V^T$}: a $m\times d$ matrix
                \item \emph{$\mathcal{D}$}: a $t\times m$ matrix containing all the terms of the relevant documents
                \item \emph{$\mathcal{T}$}: a $m\times d$ matrix containing the query terms useful for calculating the cosine similarity with the terms present in $\mathcal{D}$
            \end{itemize}
        \end{minipage}
    \end{minipage}9
\end{frame}

\begin{frame}{QUERY EXPANSION}
    After calculating the cosine similarity between the word vectors of the 
    relevant documents and the word vectors of the query, a maximum of ten 
    most similar words are selected for each single word in the query. Starting 
    from this assumption, by making a combination between the pairs of 
    words ($q_t$, $d_n$), the maximum number of new queries that can be 
    generated is: 
    $$ \#Queries = \prod_i^q (\#sim\_words_i) $$
    Where \emph{q} represents the number of tokens of the query and \emph{$\#sim\_words_i$} 
    represents the number of tokens most similar to each single token \emph{i} of the 
    query. Obviously some checks are made (eg word repetition), which may 
    not cause the query to be generated.
\end{frame}


\begin{frame}{PERPLEXITY}
    
\end{frame}

\begin{frame}{SYSTEM EVALUATION WITH DIFFERENT PARSERS}
    
\end{frame}

\begin{frame}{CONCLUSIONS}
    
\end{frame}







